{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementClickInterceptedException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/HP/Desktop/Data Trained/Flip Robo/Web-scrapping_2 (1).ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer starts from below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()\n",
    "time.sleep(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst - Supporting Audits',\n",
       " 'Business/Data Analyst - Colleague Experience & Technology']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a[1]\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru', 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visa Inc.', 'Vmware']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-8 Yrs', '3-8 Yrs']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-8 Yrs</td>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Analyst - Supporting Audits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business/Data Analyst - Colleague Experience &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Enquero</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Analyst - Einstein Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>NIUM INDIA PRIVATE LIMITED</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...</td>\n",
       "      <td>Data Analyst - 0-2 years (6 month contract)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>CAREERLABS TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                             company_name  \\\n",
       "0             2-8 Yrs                                Visa Inc.   \n",
       "1             3-8 Yrs                                   Vmware   \n",
       "2             3-5 Yrs                                  Enquero   \n",
       "3             0-2 Yrs               NIUM INDIA PRIVATE LIMITED   \n",
       "4             0-3 Yrs  CAREERLABS TECHNOLOGIES PRIVATE LIMITED   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "3  New Delhi, Gurgaon/Gurugram, Chennai, Bangalor...   \n",
       "4                                 (WFH during Covid)   \n",
       "\n",
       "                                           job_title  \n",
       "0            Senior Data Analyst - Supporting Audits  \n",
       "1  Business/Data Analyst - Colleague Experience &...  \n",
       "2           Senior Data Analyst - Einstein Analytics  \n",
       "3        Data Analyst - 0-2 years (6 month contract)  \n",
       "4                                       Data Analyst  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done\n",
    "manually.\n",
    "WEB SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist- Senior Business Analyst/Lead Analyst',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evalueserve.com Pvt. Ltd', 'Signify']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram, Bangalore/Bengaluru', 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist- Senior Business Analyst/Lead A...</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Job Description\\nUnderstand and design analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Signify</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>What you ll do\\nResearch, design and prototype...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Retail Industry</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist (Analytics),</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data and Analytics Proposal Responses for Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior/ Lead Data Scientist</td>\n",
       "      <td>Superior Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Provide advanced analytical capabilities to su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Data Scientist- Senior Business Analyst/Lead A...   \n",
       "1                              Senior Data Scientist   \n",
       "2              Lead Data Scientist - Retail Industry   \n",
       "3                 Senior Data Scientist (Analytics),   \n",
       "4                        Senior/ Lead Data Scientist   \n",
       "\n",
       "               company_name                           job_location  \\\n",
       "0  Evalueserve.com Pvt. Ltd  Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                   Signify                    Bangalore/Bengaluru   \n",
       "2    IBM India Pvt. Limited                    Bangalore/Bengaluru   \n",
       "3                    Luxoft                    Bangalore/Bengaluru   \n",
       "4            Superior Group                    Bangalore/Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job Description\\nUnderstand and design analyti...  \n",
       "1  What you ll do\\nResearch, design and prototype...  \n",
       "2                                                ---  \n",
       "3    Data and Analytics Proposal Responses for Cr...  \n",
       "4  Provide advanced analytical capabilities to su...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":job_description[0:10]})\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Description\\nUnderstand and design analytical solutions to business problems leveraging data science\\nUnderstand and get requirements from Stakeholders\\nPropose and execute solutions and present deliverables to stakeholders\\nManage and optimize deliverables\\nMentor and train new team members\\nDevelop POCs to enhance the teams capability\\n\\nRequirements\\nUnderstanding of mathematical, statistical, and theoretical foundations of statistics and machine learning (ML) and parametric and non-parametric models\\nKnowledge of advanced data mining techniques, curating, processing, and transforming data to produce datasets\\nUse statistical techniques and ML methods for predictive modeling / classification of problems around clients, distribution, sales, marketing, client profiles, and segmentation\\nProvide relevant and actionable recommendations / insights for businesses\\nUnderstanding of ML lifecycle that includes feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loop\\nExpertise in SAS Visual Analytics, Tableau, and Python\\nExpert in Python / R / SAS\\nExperience with cloud computing infrastructure, such as AWS / Azure / GCP\\nAble to develop, test, and deploy models on cloud / web\\n\\nEducation and Experience\\nBE / B.Tech. / MBA / M.Stat. / M.SC. or equivalent degree in Quant. from a reputed institute\\n2-8 years of relevant experience',\n",
       " 'What you ll do\\nResearch, design and prototype robust and scalable models based on machine learning, data mining, and statistical modeling to answer key business problems\\nBuild tools and support structures needed to analyze data, perform elements of data cleaning, feature selection and feature engineering and deliver projects in conjunction with best practices\\nWork with development teams business groups to ensure models can be implemented as part of a delivered solution and can be replicated across multiple markets / countries\\nPresent findings to stakeholders to drive improvements and solutions from concept through to delivery\\nKeep abreast of the latest developments in the field by continuous learning and proactively champion promising new methods relevant to the problems at hand\\nWhat you ll need\\nPhD / Masters / B.Tech in computer science, computer engineering with 7+ years of demonstrated experience in the Advanced Analytics / Machine Learning field\\nDemonstrated history of driving and delivering analytics models and solutions\\nDeep knowledge of fundamentals of machine learning, data mining and statistical modeling, and extensive experience applying these methods to real world problems\\nStrong skills in software prototyping and engineering with expertise in applicable programming and analytics languages (Python, R, SQL) and various open source machine learning and analytics packages. Good knowledge of SAP Datahub is highly desired\\nAbility and inclination to work in multi-disciplinary environments, and desire to see ideas realize in practice\\nWhat you ll get in return\\nOpportunity to work on some of the highly complex and challenging business problems across a variety of functional domains and consumer markets\\nCompetitive salary depending on experience\\nExtensive set of tools to drive your career, such as a personalized learning platform, free training and coaching',\n",
       " '---',\n",
       " '  Data and Analytics Proposal Responses for Cross Industry Solutions.\\nThe position is for the global client solutioning team. Analytics client solutioning team supports various Analytics opportunities, which mainly includes RFP responses, Analytics technical consulting etc.\\n\\nWe are a global team and we provide Analytics solutioning support from India spanning across all regions globally.\\n\\nOur current openings are for the Solution Architects, who can provide solutions like:\\n- Data Engineering This includes data engineering solutioning and data management solutioning ( Both on Premise and on Cloud solutions)\\n- Data Modernization This involves Analytics workload migration to cloud solutions , Analytics modernization (end-to-end).\\n- Analytics AI - This involves solutioning Advanced analytics models / solutions spanning across all Industries\\n\\n\\nResponsibilities\\nGlobal Analytics Client Solutioning -\\nResponsible for constructing responses to Analytics Solutions as response to RFP\\nResponsible for providing consulting services on Analytics\\nResponsible for Analytics Solutions as response to RFP\\n\\n\\nSkills\\nMust have\\n9+ years working as a Data Scientist with Lead experience.\\nMSc or PhD in machine learning, computer science, mathematical science or similar.\\nExperience in Solutioning Business requirements into fully operationalized AI / ML Projects\\nExperience in leading data science engagements and/or other data scientists within a project.\\nAble to articulate complex data science concepts to both technical and non-technical audiences\\nExperience in Deep Learning and other Machine Learning techniques (e.g. regression, classification, topic modelling, time series, Neural Networks).\\nExposure / Knowledge in all Data Science offerings (Machine Learning, Anomaly Detection, Text Analytics / NLP, Computer Vision, Deep Learning)\\nStrong Experience with machine learning in Python, SQL, Pandas, Numpy, Scikit Learn, Tensorflow, Keras, PyTorch or equivalent\\nShould be able to drive creation of PoCs and contribute to CoEs working with the Delivery team\\nShould have sound understanding of Agile, DevOps, CI/CD, source control and automated testing\\nExpertise in ML Ops Deployments in one or more projects\\nExperience of working in cloud environments (Azure, GCP, AWS etc)\\nSpark / Hive/ Big Data Tools (Athena/Big Query etc...)\\nStrong domain expertise in 1 or more industry or have exposure to multiple business process scenario\\nExcited about data science!\\nNice to have\\nShould have sound understanding of Agile, DevOps, CI/CD, source control and automated testing\\nExperience of working in cloud environments (Azure, GCP, AWS etc)\\nSpark / Hive/ Big Data Tools (Athena/Big Query etc...)\\n\\n ',\n",
       " 'Provide advanced analytical capabilities to support data science initiatives\\nSolves highly complex problems that do not yet have solutions in the research and span much of the Data Science portfolio\\nInfluences the thought process and methodology for other team members\\nJob Requirements\\nSkill seet required:\\n6+ years of experience in analytics AND 2 years of programming experience (Python, Java, Scala, Rust, etc.)\\n3 years of experience performing predictive analytics at a large scale enterprise\\n3 years of experience in data science or advanced analytics in industry\\nSQL Experience\\nExperience using multiple data systems and sources (such as Hadoop, Spark, Aster, Teradata, etc.)',\n",
       " 'Looking to hire a Consultant in Analytics team to implement analytics projects like data mining, forecasting, predictive models, social media analytics and contextual analytics.\\nSpecification / Skills / Experience\\n• Work independently on complex analytics projects, specifically on projects involving building and implementing statistical models\\n• Ability to understand business needs and apply analytical concepts to provide business solutions\\n• Oversee execution and delivery of key project milestones.\\n• Accountable for clear requirements documentation, analysis/development plans, project consulting and troubleshooting, the on time delivery of projects, timely communication to clients, and quality of project deliverables.\\n• Project management tasks include (but are not limited to): defining project scope, assisting with requirements collection, providing analysis/development plans, working closely with the client both onshore and offshore during execution of project, and ensuring on-time delivery of and quality of projects.\\n• Establish and maintain clear communication with the team manager regarding project scope, timelines, issue resolution, and deliverables.\\n• Ability to adapt to analytics requirements across multiple functions (Marketing, Sales, Supply Chain) and multiple industries (Utilities, Insurance, Financial Services, Life Sciences etc.)\\n• Ability to work in a multi-cultural environment and independently handle clients across geographies\\n\\nPrimary Skills (Must have)\\n• Overall 2-4 years of analytics experience, preferably across multiple domains (marketing, sales, supply chain) or multiple industries (utilities, insurance, financial services, retail, life sciences)\\n• Experience in utilizing statistical tools (e.g., SAS, SPSS, R Programming, SQL)\\n• Strong experience in advanced statistics and analytics including segmentation, modeling, regression, forecasting etc.\\n• Strong business understanding of at least one domain/industry\\n• Exposure in working directly with clients to conceptualize, design and deliver high-quality solutions and insightful analysis on a variety of projects ranging in both complexity and scope\\n• Excellent communications skills with respect to translating business needs into a mathematical/data analysis approach and translating analysis results back into business terms.\\n• Ability to synthesize and clearly communicate highly complex findings that focus on the critical issues and provide actionable opportunities.\\n• Ability to work in a cross cultural environment\\n• Proven project successes, including balancing multiple projects and differing project priorities.\\n• Desired Previous consulting analytics experience preferred',\n",
       " '---',\n",
       " 'Exp : 5 `to 9 yrs\\nSkill : Data Scientist\\nJD:\\nDelivery Excellence has identified Predictive Analytics as one of the top focus areas. By looking through the vast amount of structured and unstructured data to identify patterns, draw inferences and predict outcomes, we intend to enhance the delivery quality, operations & risk management capability in client engagements leading to enhanced profitability, revenue & client satisfaction.\\nWe are looking for a Data Scientist to join our team to provide the subject matter expertise and technical leadership in this endeavor. He / She will collaborate with the business teams, technical & functional teams, and vendor partners to understand the needs and devise solutions. He / She will evaluate alternate approaches, models & toolkits to define suitable solutions based on the problem statements.\\n\\nRole\\nData Scientist\\nKey Responsibilities\\nDiscover the information hidden in structured & unstructured data by applying data mining techniques, doing statistical analysis, and building high quality prediction systems\\nEvaluating business problems for suitability & feasibility of a predictive solution\\nEvaluating & Identifying the right Machine Learning and data science techniques & toolsets to address a variety of predictive analytics problems\\nAn individual contributor as well as a guide to the fellow team members in discovery, design, and development of analytical models\\nWorking with functional & technical teams in the development, pilot & optimization of tools and models using Machine Learning & Natural Language Processing\\nQualifications & Skills\\nAdvanced degree in statistics, computer science, machine-learning or related fields such as econometrics\\n10+ years of professional experience in software engineering, with a good understanding of the Information Technology industry\\n5+ years of data mining (structured / unstructured data) & Machine Learning experience, with a proven ability to design and develop solutions across ML landscape (supervised, un-supervised, semi-supervised etc.)Excellent applied statistics skills\\nSupervised algorithms, such as k-NN, Naive Bayes, Decision Trees, Logistic Regression, SVM, Random Forests, Neural Nets etc.\\nUnsupervised algorithms including clustering, anomaly detection, document similarity, dimensionality reduction etc.\\nProven experience with below toolkits & technologies is a must: Statistical programming languages such as Python, R\\nAzure Machine Learning\\nML and NLP toolkits such as scikit-learn, TensorFlow, PyTorch, Keras, Stanford suite, Python NLTK, spaCy\\nStrong attention to detail and excellent quantitative and qualitative analytical ability\\nTeam player and a self-starter; Excellent collaboration skills\\nExcellent oral & written communication skills, with ability to explain machine learning concepts and findings or techniques to varied stakeholders\\nShift : Day Job\\nTravel : No',\n",
       " '---',\n",
       " 'Roles and Responsibilities\\nStrong in problem solving, algorithms and data structures\\nProficient in Python\\nHands on experience in technologies and tools related NLP, Deep learning, Machine learning\\nExperience on Conversational AI is a plus\\nAble to train and deploy models. Hands on experience on multi gpu/ tpu training\\nBroad knowledge of machine learning algorithms and principles\\nPerformance profiling and Tuning\\nCommunicate and propose solutions to business challenges\\nFamiliarity with at least one of the cloud computing infrastructure - GCP/AWS\\nKeep abreast with the latest technological advances\\nTeam mentoring and leadership skills\\n\\nDesired Candidate Profile\\n\\nNo. of opening: 01\\nExperience Required : 05 years and above\\nEducational Qualification: B.E/ B.Tech from Top Tier institutes ( IIT, BITS and NITs)\\nExperience with Product company\\nMust be interested to work in a fast pace startup culture\\n\\nPerks and Benefits\\nMedical coverage for Self and Family\\nProvident Fund\\nStock Options\\nLearning Program']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the location check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the salary check box\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "\n",
    "# clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Immediate Openings For DATA Scientist with 6 To 7 yrs of Experience']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs', '5-8 Yrs']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    " #scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>inVentiv International Pharma Services Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>(29 Reviews)</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-7 Yrs</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Ahmedabad, Ba...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>(11 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Experiture</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                                      company_name  \\\n",
       "0             3-6 Yrs  inVentiv International Pharma Services Pvt. Ltd.   \n",
       "1             5-8 Yrs                                      (29 Reviews)   \n",
       "2             5-7 Yrs              Entune IT Consulting Private Limited   \n",
       "3             2-4 Yrs                                      (11 Reviews)   \n",
       "4             3-6 Yrs                                        Experiture   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "2  Kolkata, Hyderabad/Secunderabad, Ahmedabad, Ba...   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "\n",
       "                                           job_title  \n",
       "0                              Senior Data Scientist  \n",
       "1  Immediate Openings For DATA Scientist with 6 T...  \n",
       "2                                     Data Scientist  \n",
       "3                                     Data Scientist  \n",
       "4                                     Data Scientist  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "WEB SCRAPING ASSIGNMENT-2\n",
    ".\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to login  manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.keyword']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.location']\"))).send_keys(\"Noida\")\n",
    "\n",
    "\n",
    "#search_field_designation=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "#search_field_designation.send_keys(\"Data Scientist\")\n",
    "#search_field_location=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "#search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Applied Materials Inc.', 'Hy.ly Inc.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where company name is present\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0', '3.4']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where ratings of the company  is present\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "company_ratings[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '1']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the element where  No. of days ago when job was posted is present\n",
    "days=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text[0])\n",
    "days_ago[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hy.ly Inc.</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lunavo Labs/Swazei</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slice</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company_name company_ratings days_ago\n",
       "0  Applied Materials Inc.             4.0        3\n",
       "1              Hy.ly Inc.             3.4        1\n",
       "2      Lunavo Labs/Swazei             4.4        4\n",
       "3                   Ambee             3.0        3\n",
       "4                   Slice             5.0        5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]\n",
    "                })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount \n",
    "To scrape \n",
    "the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "#search_bar.clear()\n",
    "search_bar.send_keys('sunglasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the required products links\n",
    "link=[]\n",
    "while len(link) <= 100:\n",
    "    product_link=driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\")\n",
    "    for lnk in product_link:\n",
    "        link.append(lnk.get_attribute('href'))\n",
    "    #going for next 3 pages\n",
    "    try:\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        nxt_button.click()#getting the link from the list for next page\n",
    "    except ElementClickInterceptedException:\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver.get(nxt_button.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrapping the required details\n",
    "try:\n",
    "    for page in link[:100]:#for loop for scrapping 100 products\n",
    "        driver.get(page)\n",
    "        brands=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")#scraping brands name by class name='_2B_pmu'\n",
    "        brand.append(brands.text)#appending the text in Brand list\n",
    "        desc=driver.find_elements_by_xpath(\"//span[@class='B_NuCI']\")#scraping description\n",
    "        for i in desc:\n",
    "            description.append(i.text.replace('\\n',''))#appending the description in list\n",
    "        prices=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")# scraping the price from the xpath\n",
    "        price.append(prices.text)\n",
    "        discnt=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")# scraping the discount from the xpath\n",
    "        discount.append(discnt.text)\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Brand                                        Description Price  \\\n",
      "0        ROYAL SON   Polarized, UV Protection Round Sunglasses (49)...  ₹699   \n",
      "1        ROYAL SON   Polarized, UV Protection Round Sunglasses (49)...  ₹699   \n",
      "2          Billion   UV Protection, Riding Glasses Wrap-around Sung...  ₹279   \n",
      "3           PIRASO   UV Protection Aviator Sunglasses (54)  (For Me...  ₹237   \n",
      "4         Fastrack   UV Protection Rectangular Sunglasses (Free Siz...  ₹513   \n",
      "..              ...                                                ...   ...   \n",
      "95       Elligator   Mirrored Round Sunglasses (53)  (For Men & Wom...  ₹312   \n",
      "96       ROYAL SON   UV Protection Over-sized Sunglasses (65)  (For...  ₹699   \n",
      "97        Fastrack   Gradient, UV Protection Wayfarer Sunglasses (F...  ₹509   \n",
      "98        Fastrack   Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹738   \n",
      "99  ROZZETTA CRAFT   UV Protection, Gradient Rectangular Sunglasses...  ₹404   \n",
      "\n",
      "   Discount  \n",
      "0   65% off  \n",
      "1   78% off  \n",
      "2   85% off  \n",
      "3   35% off  \n",
      "4   15% off  \n",
      "..      ...  \n",
      "95  53% off  \n",
      "96  36% off  \n",
      "97  26% off  \n",
      "98  79% off  \n",
      "99  65% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the required products links\n",
    "link=[]\n",
    "while len(link) <= 100:\n",
    "    product_link=driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\")\n",
    "    for lnk in product_link:\n",
    "        link.append(lnk.get_attribute('href'))\n",
    "    #going for next 3 pages\n",
    "    try:\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "        nxt_button.click()#getting the link from the list for next page\n",
    "    except ElementClickInterceptedException:\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver.get(nxt_button.get_attribute('href'))\n",
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the required details\n",
    "try:\n",
    "    for page in link[:100]:#for loop for scrapping 100 products\n",
    "        driver.get(page)\n",
    "        brands=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")#scraping brands name by class name='_2B_pmu'\n",
    "        brand.append(brands.text)#appending the text in Brand list\n",
    "        desc=driver.find_elements_by_xpath(\"//span[@class='B_NuCI']\")#scraping description\n",
    "        for i in desc:\n",
    "            description.append(i.text.replace('\\n',''))#appending the description in list\n",
    "        prices=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")# scraping the price from the xpath\n",
    "        price.append(prices.text)\n",
    "        discnt=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")# scraping the discount from the xpath\n",
    "        discount.append(discnt.text)\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Brand                                        Description  \\\n",
      "0            DUCATI                            Sneakers For Men  (Grey)   \n",
      "1         Marc Ecko                           Sneakers For Men  (Brown)   \n",
      "2            Chevit   Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
      "3    luxury fashion                           Sneakers For Men  (White)   \n",
      "4        Shoes Bank   White Sneaker For Men's/Boy's Sneakers For Men...   \n",
      "..               ...                                                ...   \n",
      "95           DUCATI                           Sneakers For Men  (Black)   \n",
      "96         ASTEROID   Original Luxury Branded Fashionable Men's Casu...   \n",
      "97         ASTEROID   Original Luxury Branded Fashionable Men's Casu...   \n",
      "98           Chevit   Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
      "99  U.S. POLO ASSN.            LEBRON 2.0 Sneakers For Men  (Off White)   \n",
      "\n",
      "     Price Discount  \n",
      "0   ₹1,189  66% off  \n",
      "1     ₹479  78% off  \n",
      "2     ₹599  62% off  \n",
      "3     ₹448  65% off  \n",
      "4     ₹349  65% off  \n",
      "..     ...      ...  \n",
      "95  ₹1,219  67% off  \n",
      "96    ₹499  75% off  \n",
      "97    ₹499  50% off  \n",
      "98    ₹473  73% off  \n",
      "99  ₹3,916   2% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10:  Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising driver\n",
    "driver.get(' https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception\n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")#locating the ratingd link\n",
    "        rate.click()                                                      #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "print(len(Title))\n",
    "print(len(price))\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     Price       Ratings\n",
      "0  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  1,99,990  2.9 out of 5\n",
      "1  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  1,07,990  4.5 out of 5\n",
      "2  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990  4.3 out of 5\n",
      "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...    59,490  4.4 out of 5\n",
      "4  ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...    71,990  3.8 out of 5\n",
      "5  HP Pavilion Gaming(2021) 10th Gen Intel Core i...    89,990  4.4 out of 5\n",
      "6  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...    73,990  4.4 out of 5\n",
      "7  MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....    81,990  3.7 out of 5\n",
      "8  Lenovo Legion 5 10th Gen Intel Core i7-10750H ...    82,990  4.4 out of 5\n",
      "9  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    34,990  3.6 out of 5\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6337.0_10225.0_6337.0%20TO%2010225.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Brand                       Short-description  \\\n",
      "0                   ALDO                       Men Driving Shoes   \n",
      "1                   Nike          Men Flex Run 2021 Running Shoe   \n",
      "2           UNDER ARMOUR                Men Charged Pursuit 2 SE   \n",
      "3           UNDER ARMOUR             Men HOVR Sonic 4 Colorshift   \n",
      "4           UNDER ARMOUR             Unisex Project Rock Recruit   \n",
      "5           UNDER ARMOUR          Men HOVR Sonic 4 Running Shoes   \n",
      "6                   Nike              Men BlazerLow '77 Sneakers   \n",
      "7                   Nike             Men AIR ZOOM PEGASUS 38 Run   \n",
      "8           UNDER ARMOUR          Men Charged Pursuit 2 SE Shoes   \n",
      "9             PUMA Hoops           Unisex Clyde Basketball Shoes   \n",
      "10                  Puma               Mesh Hybrid Fuego Running   \n",
      "11          UNDER ARMOUR          Women Charged Bandit 6 Running   \n",
      "12                  Puma            Women Velocity Nitro Running   \n",
      "13          UNDER ARMOUR           Men Charged Commit 3 Training   \n",
      "14          Hush Puppies            Men Leather Slip-On Sneakers   \n",
      "15  Heel & Buckle London                    Men Leather Sneakers   \n",
      "16          UNDER ARMOUR                 Men Phade Running Shoes   \n",
      "17          UNDER ARMOUR             Men Charged Assert 8 Marble   \n",
      "18              Skechers                 Men Equalizer 4.0 Trail   \n",
      "19          UNDER ARMOUR                 Women HOVR Sonic 4 FnRn   \n",
      "20          UNDER ARMOUR             Men Charged Rogue 2.5 RFLCT   \n",
      "21          UNDER ARMOUR               GS SC 3Zero IV Basketball   \n",
      "22               Bugatti                    Men Slip-On Sneakers   \n",
      "23                  Puma              Men Velocity Nitro Running   \n",
      "24          UNDER ARMOUR              Women HOVR Sonic 4 Running   \n",
      "25  FORCLAZ By Decathlon                      TREKKING 100 Boots   \n",
      "26                  Puma                 Men SOFTRIDE Rift Shoes   \n",
      "27                  Puma          Unisex Connect Splash Trainers   \n",
      "28                  Puma            Unisex Future Rider Sneakers   \n",
      "29                  Geox            Men Leather Slip-On Sneakers   \n",
      "30  Quechua By Decathlon                      Men Trekking Shoes   \n",
      "31          Hush Puppies       Men Solid Leather Formal Slip-Ons   \n",
      "32                  Puma            Women Eternity Nitro Running   \n",
      "33          UNDER ARMOUR               Men HOVR Infinite Running   \n",
      "34                  Nike             Women AIR MAX VIVA Sneakers   \n",
      "35          UNDER ARMOUR           Women Charged Rogue 2.5ClrSft   \n",
      "36               Bugatti                            Men Sneakers   \n",
      "37             Cole Haan                     Women Solid Loafers   \n",
      "38          UNDER ARMOUR          Women Charged Assert 8 Running   \n",
      "39  Heel & Buckle London               Men Tassel Leather Loafer   \n",
      "40              DAVINCHI  Men Solid Formal Leather Slip-On Shoes   \n",
      "41                  Geox      Men Textured Leather Driving Shoes   \n",
      "42                  Geox               Men Leather Driving Shoes   \n",
      "43                  Geox          Men Perforated Slip On Sneaker   \n",
      "44             J.FONTINI            Men Textured Leather Loafers   \n",
      "45                  Geox                  Women Leather Sneakers   \n",
      "46                  Geox            Men Printed Slip-On Sneakers   \n",
      "47  Heel & Buckle London              Men Leather Formal Loafers   \n",
      "48                  Geox              Men Leather Formal Oxfords   \n",
      "49             J.FONTINI            Men Textured Leather Loafers   \n",
      "\n",
      "                          Price  \n",
      "0                     Rs. 11999  \n",
      "1                      Rs. 6795  \n",
      "2                      Rs. 6999  \n",
      "3                     Rs. 10999  \n",
      "4                      Rs. 9999  \n",
      "5                     Rs. 10999  \n",
      "6                      Rs. 7195  \n",
      "7                      Rs. 9995  \n",
      "8                      Rs. 6999  \n",
      "9    Rs. 7149Rs. 10999(35% OFF)  \n",
      "10                     Rs. 6999  \n",
      "11                     Rs. 8999  \n",
      "12   Rs. 7149Rs. 10999(35% OFF)  \n",
      "13                     Rs. 7999  \n",
      "14    Rs. 6999Rs. 9999(30% OFF)  \n",
      "15   Rs. 7693Rs. 10990(30% OFF)  \n",
      "16                     Rs. 6499  \n",
      "17                     Rs. 6999  \n",
      "18                     Rs. 6499  \n",
      "19                    Rs. 10999  \n",
      "20                     Rs. 7999  \n",
      "21                     Rs. 7499  \n",
      "22    Rs. 6399Rs. 7999(20% OFF)  \n",
      "23                    Rs. 10999  \n",
      "24                    Rs. 10999  \n",
      "25                     Rs. 6999  \n",
      "26                     Rs. 6499  \n",
      "27                     Rs. 8999  \n",
      "28                     Rs. 6999  \n",
      "29                     Rs. 9490  \n",
      "30                     Rs. 9999  \n",
      "31    Rs. 8099Rs. 8999(10% OFF)  \n",
      "32   Rs. 8449Rs. 12999(35% OFF)  \n",
      "33                    Rs. 11999  \n",
      "34   Rs. 8121Rs. 12495(35% OFF)  \n",
      "35                     Rs. 7999  \n",
      "36                     Rs. 7999  \n",
      "37  Rs. 10799Rs. 17999(40% OFF)  \n",
      "38                     Rs. 6999  \n",
      "39   Rs. 9093Rs. 12990(30% OFF)  \n",
      "40                     Rs. 6990  \n",
      "41                     Rs. 9999  \n",
      "42                     Rs. 9990  \n",
      "43    Rs. 6749Rs. 8999(25% OFF)  \n",
      "44                     Rs. 7990  \n",
      "45    Rs. 6749Rs. 8999(25% OFF)  \n",
      "46   Rs. 8249Rs. 10999(25% OFF)  \n",
      "47    Rs. 6993Rs. 9990(30% OFF)  \n",
      "48                    Rs. 10490  \n",
      "49                     Rs. 6990  \n"
     ]
    }
   ],
   "source": [
    "start_page=0\n",
    "end_page=0\n",
    "for page in range(start_page,end_page+1): \n",
    "    nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    \n",
    "    #creating empty lists\n",
    "    shoe_names=[]\n",
    "    s_desc=[]\n",
    "    short_desc=[]\n",
    "    price=[]\n",
    "    \n",
    "    #for scrapping shoe brand names\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    #for scrapping shoe short-description\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    #for scrapping shoe prices\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in desc:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #for scrapping the datas from next pages.\n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "    #creating a dataframe to store above scraped details\n",
    "    df=pd.DataFrame({'Brand': shoe_names,\n",
    "                    'Short-description': short_desc,\n",
    "                    'Price': price})\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
